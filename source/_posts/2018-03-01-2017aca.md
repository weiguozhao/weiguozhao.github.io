---
layout: post
title: 2017开放学术精准画像大赛
date: 2018-03-01 12:10 +0800
categories: 数据竞赛
tags:
- 算法
- 技术
- 比赛
mathjax: true
copyright: true
---

**队伍名：ICRC@HITSZ，获决赛第三名(3/412)**，[大赛主页](https://biendata.com/competition/scholar/)

![results](/posts_res/2018-03-01-2017aca/results.png)

**本文是对比赛的思路等的整理，包含后期参考其他队的思路**


目录

* Task 1 学者画像信息抽取
* Task 2 学者兴趣标签预测
* Task 3 学者未来影响力预测
* 评测方案


------------

### Task 1 学者画像信息抽取

#### Task 1 赛题

学者画像信息具体包括学者的主页地址、性别、职位等。随着互联网越来越普及，与学者相关的网页的数量和内容的丰富度和复杂度都大大增加，其中包含了学者的大量冗余信息，通过整合互联网上多种来源的学者数据，采用合适的机器学习模型，获得学者的精准信息是一项潜在有效的学者画像技术。

给定学者姓名、学者所属机构，以及谷歌搜索关键字“学者姓名＋机构”返回的第一页搜索结果的缓存页面的URL（静态页面，一般包含10条搜索结果），同时允许参赛者访问其中每条搜索结果的网页链接以及该网页内的链接，要求抽取学者的个人主页URL、学者头像URL、邮箱地址、性别、职称/职位列表，以及学者当前所属机构所在国家。

示例:

```text
输入：
scholar name: Jiawei Han
organization name: UIUC
search results page: http://xxx.xxx/xxx.html

输出：
homepage: http://hanj.cs.illinois.edu/ (注释: 从搜索结果中找)
pic: http://hanj.cs.illinois.edu/images/hanj_tour.jpg (注释: 从个人主页中找)
email: hanj[at]cs.uiuc.edu (注释: email的格式跟学者个人主页中保持一致)
gender: m (注释: m 代表 male, f 代表 female)
position: Abel Bliss Professor (注释: 需要跟个人主页中的格式保持一致)
location: USA (注释: 需要跟个人主页中的格式保持一致)
```

<br>

#### Task 1 思路

**个人主页URL**

对于个人主页搜索结果的每条记录提取特征后进行是否是主页的分类，其中概率最高的被判断为个人主页。

特征如下：
1. 网站在搜索结果中的排名；-> 1
2. 学者所在机构是否为大学/学校；-> 1
3. 搜索结果标题/摘要以及学者所在机构的文本长度 -> 3
4. url中是否包含给定关键词(社交类linkedin……、论文类spring……、正向词homepage……)，对每个部分做平均值为特征； -> 35
5. 搜索结果摘要中是否包含mail，address； -> 2
6. 搜索结果的标题/摘要中的学者姓名得分。这里将学者姓名分词为n份，如果其中m份在文本中出现，那么姓名的得分就是 m/n，同时增加完整名字在标题摘要中出现的得分； -> 1

```text
一级负向词
'facebook', 'linkedin', 'twitter', 'youtube', 'instagram', 'quora', 'blots', 
'dl.acm', 'arxiv', 'ieeexplore', 'springer', 'webofknowledge', 'library', 
'researchgate', 'books.google', 'netprofile', 'cnki', 'ted.com', 'antpedia', 
'academictree', 'phdtree', 'shguang.net', 'airbnb', 'bloomberg', 'pinterest', 
'weibo', 'hmetmer', 'peekyou', 'mitbbs', 'schneier.com', 'directory.ubc.ca', 
'citation', 'videolectures', 'slideshare', 'brokercheck.finra.org',

二级负向词
'pdf', 'news', 'report', 'scholarmate', 'journals', 'ratemyprofessors',
'doc', 'conference', 'wiki', 'scholar', 'book', 'publication', 'github', 'crunchbase',
'group', 'scholarmate', 'google', 'stories', 'story', 'relationshipscience',

正向词
'~', 'edu', 'home', 'faculty'
```

由于正负样本不均衡(1:9)，所以首先尝试通过**过采样**的方式进行处理。具体如下：

1. 重复增加正样本的数量，尝试通过XGBoost模型及SVM模型进行分类，最终在训练集中的效果有提升，但在测试集上变化不大；
2. (未实现)尝试通过[SMOTE算法](/2018/06/smote)进行过采样。

鉴于第一种方式的效果并不明显，分析由于样本特征比较少(43维)，导致出现了过拟合的现象出现。

接下来尝试通过**负采样**的方式进行解决，具体如下：

1. 因为负样本数量多，进行随机选择，构造新的训练数据集；
2. 通过XGBoost模型及SVM模型进行分类，效果明显得到提升。

其中XGBoost效果比SVM效果稍微好一点。
1. XGBoost可以自适应非线性：随着决策树的生长，能够产生高度非线性的模型，而SVM等线性模型的非线性化需要基于核函数，要求学习之前就要定好核函数，然而确定核函数并不是一件容易的事；
2. 多分类器隐含正则项：XGBoost自带正则化项（包含叶结点数量等），SVM通常需要增加L2正则
3. 真实世界的数据具有特征多样性的特点，SVM本质是一个几何模型，需要人为去定义样例之间的核函数或者相似性；
4. 多种可调的参数，效率、灵活、易用方面，XGBoost都有比较好的交互使用。

最终我们在个人主页上的测试集取得了0.74的准确率，考虑到数据噪声以及搜索结果中多个正确主页的存在，真实的准确率应该接近0.85。


**性别**

主要通过学者的名字进行判断。通过网上的开源姓名性别数据，训练了一个朴素贝叶斯分类器，其中用到的特征是名字的后2位到后7位字母(每一位为一维特征)，以及名字长度，名字分词长度。如果学者名字长度不足的，用空格填充。

结果上能取得0.9的准确率。


**邮箱**

主要通过正则表达式进行识别。根据[RFC2822](https://tools.ietf.org/html/rfc2822)中的邮箱标准，并结合训练集中邮箱的格式，我们写了一个很复杂的正则表达式，另外针对仍然无法获取到邮箱的，我们捕获网页中的mailto的链接来确定该学者的邮箱。

这样仍然有一部分的图片邮件或者通过加密技术加密的邮箱无法获得，针对图片邮箱，我们通过捕获图片的名称，判断是否和邮件相关，相关即取该图片的url。
对于加密邮箱，暂未想到比较合适的方法，而且这种邮箱数量比较少，所以对最终结果应该不大。


**照片**

首先利用正则表达式+xpath等手段，获取到网页中的所有图片url及图片的名称，对于图片名称是学者名字或名字一部分的图片，直接判断该图片为学者的照片；
若没有获得结果，使用开源工具[face_recognition](https://github.com/ageitgey/face_recognition)对网页的图片进行人脸识别，当该网页中的人脸数量少于阈值4的时候，选择第一个人脸照片为该学者的照片，对人脸数量大于阈值且没有获得邮箱的，认为对学者的个人主页选择错误，并将该学者的信息留空。


**职称**

通过统计训练集中的职称，并做了一些加工之后，使用正则表达式对网页的内容进行匹配。


**国家**

主要根据获取的邮箱、以及网页中出现的地址、电话、传真等地点指向性词进行判断；另外学者的名字有时也具有一定的指向性。

当无法获得有效信息时，将该信息留空。


#### 其他

因为该任务需要联网获取数据，且学者的网站服务器良莠不齐，所以实现了一个多进程并行的爬虫。主要用到的Python库如下：
1. requests
2. selenium
3. urllib.request
4. lxml
5. multiprocessing
6. bs4


-------

### Task 2 学者兴趣标签预测

#### Task 2 赛题

研究兴趣是学者画像的重要组成部分，其不仅是学者本身的研究心得或研究拓展方向的集中体现，也能从中窥视不同背景的学者对研究领域热点或学科研究趋势的关注度、敏感度的集体反映。与学者画像信息抽取类似，通过整合互联网上的大规模多源信息，可以对学者的研究兴趣进行判断。

给定学者已发表的论文信息和合著关系网络，参赛者需为每位学者标注5个最合适的兴趣标签。

示例:

```text
输入：
name: Jiawei Han

输出：
research interests: data mining, database, information networks, knowledge discovery,  machine learning
```

<br>

#### Task 2 思路

本任务主要用到论文信息中的title以及期刊，首先将论文title分别以作者和标签为单位收集在一起并打上标签

主要是基于词袋模型，以训练集作者为单位收集的标题文本，分词去停用次后使用[卡方检验](/2018/03/chisquaredtest)进一步筛选特征，按卡方值筛选了前10%的特征词作为特征，
以标签为单位收集所有相关作者的标题文本，筛选了50%的特征词作为特征。

确定文档特征词后，采用词的tf-idf作为文档向量相应位置的权重。

考虑到文本分类大多都是线性可分的最终采用sklean中的SGDClassifier，分别对上述构建的两个数据集（以作者为单位收集的文档和以标签为单位收集的文档）训练了两个模型；尝试过Stacking，sklearn中的BaggingClassifier， GridSearchCV 5 folds来寻找最优参数；

因为本任务是多标签预测，所以我们根据训练的模型为每个作者输出概率最大的n个标签以及概率(以作者为单位的模型输出24个标签做候选标签集合，以标签为单位的模型输出23个标签做候选标签集合)
训练两个模型(以作者为单位和以标签为单位)从不同的角度提取的特征，是一个相互补充，相互修正的作用；将两个模型的候选标签集合取并集，遍历候选标签集合，评价的量为每个标签两个模型预测的概率的乘积，
期间统计作者发过的论文，记录title中出现该标签的频数(限定该作者在合著名单里为2作或者3作以内)，最后在每个标签评价量上加频数 * 评价量。最终排序取top5个标签为当前作者的标签。


--------

### Task 3 学者未来影响力预测

#### Task 3 赛题

学术影响力用来衡量学者在专业理论及技术方面的影响，常用的评价指标有论文被引量，期刊影响因子、作者H指数等，其中论文被引量是一个重要而直观的指标。本任务的目的是基于学者当前的相关学术数据预测其未来某段时间内的总论文被引量。

给定学者截止到2013年底的全部论文数据（包括论文详细引用关系，详见数据描述部分），参赛者需预测学者截止至2017年6月的总被引用数.

示例:

```
输入：
name: Jiawei Han

输出：
citation number: 126147
```

<br>

#### Task 3 思路

**预处理**

papers.txt包含了学者截止2016年所有论文的数据，其中需要预测的学者隐去了2013年后所发表的论文。所以任务三只用到2013(包含2013)年前的论文数据，
对paper.txt中的学者进行统计引用数, 去除实际引用数小于统计引用数训练集中的学者。

统计发现，学者论文引用数为0的，约占整个训练集的24%，故尝试首先通过二分类，判断学者是否具有论文引用量，之后对具有论文引用量的学者进行回归预测(两次使用同样的特征)。

**特征**

1. 学者距今0,1,2,3,4,5,6,7,8,9年的文章数被引用数(cited)；
2. 学者文章被引用数的平均值，最小值，最大值；
3. 学者距今0,1,2,3,4,5,6,7,8,9,10,20,30,40,50年的引用数(reference)；
4. 学者学术年龄、学者发表的会议期刊的数量；
5. 学者的hindex以及近两年的变化值；
6. 学者的共同作者每四年中hindex的最小值,最大值,平均值,和；
7. 会议期刊文章总数，hindex，引用他人文章的最小值，最大值，平均值以及近两年的变化值；
8. 会议期刊被引用数的中最小值，最大值，平均值，和；
9. 会议期刊按被引用数排序的特征；
10. 以共同作者关系建边图的pagerank值，以及使用共同作者次数加权的weighted_pagerank(作者合作的越多，引用数越接近)；
11. 使用每篇论文title建模[LDA模型](/2018/07/ldatopic)求出每篇论文困惑度(perplexity)和主题(topic)权值，和每个topic的被引用数，得到每个作者论文按主题计算的引用数和排序结果；
12. 通过有label的训练集中作者的真实被引用数估计每篇论文的权重，然后使用每篇文章的权重来预测未知作者的权重weight1(作者的权重由其论文权重决定)；
13. 根据训练集的label和论文被引用数关系迭代训练得出每篇论文的权值，从而每个作者得到权重weight2(比起weight1使用了paper.txt统计的论文被引用数)；

**模型**

* 分类模型：XGBClassifier(训练集上统计分类准确率为92.3%)
* 回归模型：XGBoost中XGBRegressor, sklearn中的RandomForestRegressor, ExtraTreesRegressor, SVR, LinearRegressor，并对结果进行Stacking集成

**其他trick**

学者的论文被引用数的跨度很大，有0，有10W+，所以在预测的时候对标签使用了log进行平滑；


------------

### 评测方案

#### Task 1

任务1中，每个学者共有 k (在该项任务中 k = 6)项个人画像数据需要预测。这 k 个中除了职称/职位外都通过完全匹配的方式进行评测，完全匹配上得1分，否则得0分；而职称/职位由于是一个集合，所以通过Jaccard index (即两个集合交集的元素个数除以两个集合并集的元素个数) 来进行计算提取出来的集合跟标注答案给出的集合的相似度 (介于0 ~ 1之间)。一个学者的画像数据的预测值的最终得分为这 k 个的平均分。一个参赛选手在该任务上的最终得分为对各个学者的画像数据的预测得分的平均分。即：

$$
score1 = \frac{1}{kN} \sum_{i=1}^N \sum_{j=1}^k s_i
$$

其中$ s_i $表示 k 项画像数据中第 i 项的得分，取值0 ~ 1。

<br>

#### Task 2

任务2的得分score2为参赛队伍计算生成的学者兴趣与给定的学者兴趣完全相同的比例，即：

$$
score2 = \frac{1}{N} \sum_{i=1}^N \frac{\| T_i \bigcap T_i^{\ast} \|}{\| T_i^{\ast} \|}
$$

其中，N为任务2的评测集样本个数，$T_i$为计算生成的用户i 的兴趣集合,$T_i^{\ast}$为给定的用户i 的兴趣集合。

<br>

#### Task 3

任务3的得分score3用参赛队伍预测的学者被引数与给定的学者真实被引数之间的相对误差来计算来计算

$$
score3 = 1 - \frac{1}{N} \sum_{i=1}^N 
\begin{cases} 
0, \qquad \qquad \quad v_i=0, v_i^{\ast}=0 \\
\| v_i - v_i^{\ast} \| / max(v_i, v_i^{\ast}), \quad otherwise
\end{cases}
$$

其中，N 为任务3的评测集样本个数，$v_i$为用户i 的预测被引数，$v_i^{\ast}$为用户i 的真实被引数。

<br>

#### 最终得分

$$
score = score1 + score2 + score3
$$


