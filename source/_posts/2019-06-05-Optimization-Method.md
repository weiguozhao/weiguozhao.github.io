---
title: Optimization Method
tags:
- ä¼˜åŒ–ç®—æ³•
mathjax: true
copyright: true
date: 2019-06-05 18:05:24
categories: æœºå™¨å­¦ä¹ 
---

*æœ¬æ–‡æ˜¯ä»å„ä¸ªè®ºæ–‡ã€åšå®¢ã€ä¸“æ ç­‰å­¦ä¹ æ•´ç†æ‰€å¾—,å¦‚æœ‰ä»»ä½•é”™è¯¯ç–æ¼ç­‰é—®é¢˜,æ¬¢è¿è¯„è®ºæˆ–é‚®ç®±æå‡º,å¤§å®¶ä¸€èµ·å­¦ä¹ è¿›æ­¥ï¼*

## 0 ä¼˜åŒ–ç®—æ³•æ¡†æ¶

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  g_t = \nabla f(w_t)
  \tag{0-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  m_t = \phi (g_1, g_2, \cdots, g_t)
  \tag{0-2}
  $$
  $$
  V_t = \psi (g_1, g_2, \cdots, g_t)
  \tag{0-3}
  $$

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \eta_t = \frac{\alpha}{\sqrt{V_t}} \cdot m_t
  \tag{0-4}
  $$

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  w_{t+1} = w_t - \eta_t
  \tag{0-5}
  $$

**æ ¸å¿ƒåŒºåˆ«æ˜¯ç¬¬3æ­¥æ‰§è¡Œçš„ä¸‹é™æ–¹å‘,åœ¨è¿™ä¸ªå¼å­ä¸­,å‰åŠéƒ¨åˆ†æ˜¯å®é™…çš„å­¦ä¹ ç‡ï¼ˆä¹Ÿå³ä¸‹é™æ­¥é•¿ï¼‰,ååŠéƒ¨åˆ†æ˜¯å®é™…çš„ä¸‹é™æ–¹å‘ã€‚ä¸åŒä¼˜åŒ–ç®—æ³•ä¹Ÿå°±æ˜¯ä¸æ–­åœ°åœ¨è¿™ä¸¤éƒ¨åˆ†ä¸Šåšæ–‡ç« ã€‚ä¸‹æ–‡ä¼šå°†é‡è¦çš„åœ°æ–¹æ ‡çº¢æ˜¾ç¤º**


## 1. Gradient Descent Variants

### 1.1 Batch Gradient Descent

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  g_t = \nabla f(w_t)
  \tag{1.1-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  \color{red} {m_t = g_t}
  \tag{1.1-2}
  $$
  $$
  \color{red} {V_t = 1}
  \tag{1.1-3}
  $$

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \eta_t = \frac{\alpha}{\sqrt{V_t}} \cdot m_t = \alpha \cdot g_t
  \tag{1.1-4}
  $$

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\
  &= w_t - \alpha \cdot g_t
  \end{align*}
  \tag{1.1-5}
  $$
  


### 1.2 Stochastic Gradient Descent

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  \color{red}  { g_t = \nabla f(w_t; x^{(i)}, y^{(i)}) } 
  \tag{1.2-1}
  $$

  å…¶ä¸­$(x^{(i)}, y^{(i)})$è¡¨ç¤ºç¬¬$i$ä¸ªæ ·æœ¬ï¼›

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  \color{red} {m_t = g_t}
  \tag{1.2-2}
  $$
  $$
  \color{red} {V_t = 1}
  \tag{1.2-3}
  $$

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \eta_t = \frac{\alpha}{\sqrt{V_t}} \cdot m_t = \alpha \cdot g_t
  \tag{1.2-4}
  $$

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\ &= w_t - \alpha \cdot g_t
  \end{align*}
  \tag{1.2-5}
  $$


### 1.3 Mini-Bach Gradient Descent

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  \color{red}  { g_t = \nabla f(w_t; x^{(i:i+n)}, y^{(i:i+n)}) } 
  \tag{1.3-1}
  $$

  å…¶ä¸­$(x^{(i:i+n)}, y^{(i:i+n)})$è¡¨ç¤ºç¬¬$i$ä¸ªæ ·æœ¬åˆ°ç¬¬$i+n$ä¸ªæ ·æœ¬,$n$è¡¨ç¤ºmini-batchçš„å¤§å°ï¼›

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  \color{red} {m_t = g_t}
  \tag{1.3-2}
  $$
  $$
  \color{red} {V_t = 1}
  \tag{1.3-3}
  $$

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \eta_t = \frac{\alpha}{\sqrt{V_t}} \cdot m_t = \alpha \cdot g_t
  \tag{1.3-4}
  $$

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\ &= w_t - \alpha \cdot g_t
  \end{align*}
  \tag{1.3-5}
  $$


**ä¸Šè¿°ç®—æ³•å­˜åœ¨çš„é—®é¢˜ï¼š**
- å¾ˆéš¾è°ƒæ•´å‡ºä¸€ä¸ªåˆé€‚çš„learning_rate
- learning_rateçš„å˜åŒ–è§„åˆ™å¾€å¾€æ˜¯é¢„å®šä¹‰çš„,å¾ˆéš¾é€‚åº”ä¸åŒçš„æ•°æ®
- æ‰€æœ‰çš„ç‰¹å¾å…±äº«ç›¸åŒçš„learning_rate
- å±€éƒ¨æœ€æœ‰è§£çš„é—®é¢˜


---------------------------------------------------------------


## 2. Gradient Descent Optimization Algorithm

### 2.1 Gradient Descent with Momentum

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  g_t = \nabla f(w_t)
  \tag{2.1-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡,è®¡ç®—å½“å‰æ—¶åˆ»ä¸‹é™æ¢¯åº¦(*å°†æ¡†æ¶çš„ç¬¬2æ­¥å’Œç¬¬3æ­¥åˆå¹¶*)
  $$
  \color{red} {m_t = \gamma \cdot m_{t-1} + \alpha \cdot g_t }
  \tag{2.1-2&3}
  $$

  $$
  \color{red} { \eta_t = m_t }
  \tag{2.1-4}
  $$

3. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\ &= w_t - ( \gamma \cdot m_{t-1} + \alpha \cdot g_t )
  \end{align*}
  \tag{2.1-5}
  $$

ä¸€é˜¶åŠ¨é‡æ˜¯ç§»åŠ¨å¹³å‡å€¼,è¿™é‡Œ $\gamma $ çš„ç»éªŒå€¼ä¸º`0.9`ã€‚
ä»¥å†å²åŠ¨é‡çš„å’Œä¸ºä¸»,é€‚å½“åŠ ä¸Šä¸€ç‚¹å½“å‰çš„åç§»,å³è€ƒè™‘æƒ¯æ€§çš„å› ç´ ã€‚


### 2.2 Nesterov Accelerated Gradient

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°+ä¸‹æ¬¡å˜åŒ–çš„æ¢¯åº¦
  $$
  \color{red} { g_t = \nabla f(w_t - \gamma m_{t-1}) }
  \tag{2.2-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡,è®¡ç®—å½“å‰æ—¶åˆ»ä¸‹é™æ¢¯åº¦(*å°†æ¡†æ¶çš„ç¬¬2æ­¥å’Œç¬¬3æ­¥åˆå¹¶*)
  $$
  \color{red} {m_t = \gamma \cdot m_{t-1} + \alpha \cdot g_t }
  \tag{2.2-2&3}
  $$

  $$
  \color{red} { \eta_t = m_t }
  \tag{2.2-4}
  $$

3. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\ &= w_t - ( \gamma \cdot m_{t-1} + \alpha \cdot g_t )
  \end{align*}
  \tag{2.2-5}
  $$

è¿™é‡Œ $\gamma $ çš„ç»éªŒå€¼ä¸º`0.9`,åœ¨å¯¹å‚æ•°æ±‚å¯¼æ—¶,ä¸å†å’Œä¹‹å‰æ–¹æ³•ä¸€ç›´,è€Œæ˜¯å¯¹ä¸‹æ¬¡å‚æ•°æ±‚å¯¼,å³å¤šå‘å‰çœ‹ä¸€æ­¥å¯ä»¥ç”¨æ¥æŒ‡å¯¼å½“å‰æ€ä¹ˆèµ°ã€‚


### 2.3 AdaGrad

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  g_t = \nabla f(w_t)
  \tag{2.3-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  m_t = g_t
  \tag{2.3-2}
  $$
  $$
  \color{red} {V_t = \sum_{\tau = 1}^t g_{\tau}^2 }
  \tag{2.3-3}
  $$

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \begin{align*}
  \eta_t &= \frac{\alpha}{\sqrt{V_t}} \cdot m_t \\ &= \frac{\alpha}{\sqrt{ \sum_{\tau = 1}^t g_{\tau}^2 + \epsilon }} \cdot m_t
  \end{align*}
  \tag{2.3-4}
  $$

  è¿™é‡Œ$\epsilon$æ˜¯ä¸ºäº†é¿å…åˆ†æ¯ä¸º$0$,é€šå¸¸è®¾ç½®ä¸º$1e-8$ã€‚

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\ &= w_t - \frac{\alpha}{\sqrt{ \sum_{\tau = 1}^t g_{\tau}^2 + \epsilon }} \cdot m_t
  \end{align*}
  \tag{2.3-5}
  $$

ä¸åŒçš„å‚æ•°å…·æœ‰ä¸åŒçš„æ¢¯åº¦,ä»è€Œè¾¾åˆ°äº†ä¸åŒå‚æ•°å…·æœ‰ä¸åŒå­¦ä¹ ç‡çš„ç›®çš„,è¿™æ ·æ¢¯åº¦æ›´æ–°å¿«çš„å‚æ•°,å­¦ä¹ ç‡(æ­¥é•¿)ä¼šæ¸æ¸å˜å°ã€‚
åŒæ ·æœ€ç»ˆä¼šé¢ä¸´å­¦ä¹ ç‡è¿‡å°,æ¨¡å‹æ— æ³•ç»§ç»­å­¦ä¹ çš„é—®é¢˜ã€‚


### 2.4 AdaDelta

é¦–å…ˆå®šä¹‰åŠ¨æ€å¹³å‡å€¼ $\color{red}{ E[ g^2 ]\_t = \gamma E[ g^2 ]\_{t-1} + (1 - \gamma) g_t^2 }$,è¯¥å€¼ä»…å–å†³äºå½“å‰æ¢¯åº¦å€¼ä¸ä¸Šä¸€æ—¶åˆ»çš„åŠ¨æ€å¹³å‡å€¼,å…¶ä¸­$\gamma$é€šå¸¸è®¾ç½®æˆ$0.9$ã€‚

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  g_t = \nabla f(w_t)
  \tag{2.4-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  m_t = g_t
  \tag{2.4-2}
  $$
  $$
  \color{red} {V_t = E[ g^2 ]_t }
  \tag{2.4-3}
  $$

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \begin{align*}
  \eta_t &= \frac{\alpha}{\sqrt{V_t}} \cdot m_t \\ &= \frac{\alpha}{\sqrt{ E[ g^2 ]_t + \epsilon }} \cdot m_t
  \end{align*}
  \tag{2.4-4.1}
  $$

  è¿™é‡Œ$\epsilon$æ˜¯ä¸ºäº†é¿å…åˆ†æ¯ä¸º$0$ã€‚å°†åˆ†æ¯$ \sqrt{ E[ g^2 ]\_t + \epsilon} $ è®°ä¸º $\color{red}{ RMS[g]\_t} $,å®šä¹‰
  $$
  E[ \Delta g^2 ] _t = \gamma E[ \Delta g^2 ] _{t-1} + (1 - \gamma) \Delta g _t^2
  $$

  åˆ™ï¼š
  $$
  RMS[\Delta g] _t = \sqrt{ E[ \Delta g^2 ] _t + \epsilon }
  $$

  ç”¨$RMS[\Delta g]_{t-1}$ä»£æ›¿å­¦ä¹ ç‡$\alpha$,åˆ™å¼$(2.4-4.1)$å¯ä»¥è½¬åŒ–ä¸º:
  $$
  \begin{align*}
  \eta_t &= \frac{\alpha}{RMS[g] _t} \cdot g_t \\ &= \frac{ RMS[\Delta g] _{t-1} }{ RMS[g] _t } \cdot g _t
  \end{align*}
  \tag{2.4-4.2}
  $$

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\ &= w_t - \frac{RMS[\Delta g] _{t-1}}{RMS[g] _t} \cdot g_t
  \end{align*}
  \tag{2.4-5}
  $$

$\color{red}{ä¸ºä»€ä¹ˆ}$ç”¨$RMS[\Delta g]_{t-1}$ä»£æ›¿å­¦ä¹ ç‡$\alpha$??

### 2.5 RMSprop

RMSpropæ˜¯AdaDeltaç®—æ³•çš„ä¸€ä¸ªç‰¹ä¾‹ã€‚

$$
E[g^2] _t = 0.9 E[g^2] _{t-1} + 0.1 g^2_t
$$

$$
w_{t+1} = w_t - \frac{\alpha}{ \sqrt{ E[g^2] _t + \epsilon } } g_t
$$

Hintonå»ºè®®$\gamma$è®¾ç½®æˆ$0.9$,å­¦ä¹ ç‡è®¾ç½®æˆ$0.001$ã€‚


### 2.6 Adam

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  g_t = \nabla f(w_t)
  \tag{2.6-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  \color{red}{ \hat{m_t} = \beta_1 \cdot \hat{m_{t-1}} + (1 - \beta_1) \cdot g_t } \\
  \color{red}{ m_t = \frac{\hat{m_t}}{1 - \beta_1^t} }
  \tag{2.6-2}
  $$
  $$
  \color{red}{ \hat{V_t} = \beta_2 \cdot \hat{V_{t-1}} + (1 - \beta_2) \cdot g_t^2 } \\
  \color{red}{ V_t = \frac{\hat{V_t}}{ 1 - \beta_2^t } }
  \tag{2.6-3}
  $$

  å…¶ä¸­çš„$\beta_1$æ§åˆ¶ä¸€é˜¶åŠ¨é‡,$\beta_2$æ§åˆ¶äºŒé˜¶åŠ¨é‡ï¼›

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \begin{align*}
  \eta_t &= \frac{\alpha}{\sqrt{V_t}} \cdot m_t
  \end{align*}
  \tag{2.6-4}
  $$

  å…¶ä¸­å¢åŠ çš„$\epsilon$ä¸ºäº†é˜²æ­¢åˆ†æ¯ç­‰äº$0$ï¼›

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t
  \end{align*}
  \tag{2.6-5}
  $$

  ä½œè€…å»ºè®®é»˜è®¤å€¼$\beta_1 = 0.9$,$\beta_2 = 0.999$,$\epsilon = 1e-8$ã€‚


### 2.7 AdaMax

Adamaxæ˜¯Adamçš„ä¸€ç§å˜ä½“,æ­¤æ–¹æ³•å¯¹å­¦ä¹ ç‡çš„ä¸Šé™æä¾›äº†ä¸€ä¸ªæ›´ç®€å•çš„èŒƒå›´ã€‚

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  g_t = \nabla f(w_t)
  \tag{2.7-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  \color{red}{ m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t }
  \tag{2.7-2}
  $$
  $$
  \color{red}{ 
  \begin{align*}
  V_t &= \beta_2^{\infty} V_{t-1} + (1 - \beta_2^{\infty}) \| g_t \| ^{\infty} \\
  &= max( \beta_2 \cdot V_{t-1}, \| g_t \| )
  \end{align*}
  }
  \tag{2.7-3}
  $$

  å…¶ä¸­çš„$\beta_1$æ§åˆ¶ä¸€é˜¶åŠ¨é‡,$\beta_2$æ§åˆ¶äºŒé˜¶åŠ¨é‡ï¼›

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \color{red}{
  \begin{align*}
  \eta_t &= \frac{\alpha}{V_t} \cdot m_t \\
  &= \frac{\alpha}{ max( \beta_2 \cdot V_{t-1}, \| g_t \| ) } \cdot \{ \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t \}
  \end{align*}
  }
  \tag{2.7-4}
  $$

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t \\ 
  &= w_t - \frac{\alpha}{ max( \beta_2 \cdot V_{t-1}, \| g_t \| ) } \cdot \{ \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t \}
  \end{align*}
  \tag{2.7-5}
  $$

  è®ºæ–‡è¯´åˆé€‚çš„é»˜è®¤å€¼ä¸º$\alpha = 0.002, \beta_1 = 0.9, \beta_2 = 0.999$ã€‚


### 2.8 Nadam

1. è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå½“å‰å‚æ•°çš„æ¢¯åº¦
  $$
  \color{red}{ g_t = \nabla f(w_t - \frac{\alpha}{\sqrt{V_t}} \cdot m_{t-1}) }
  \tag{2.8-1}
  $$

2. æ ¹æ®å†å²æ¢¯åº¦è®¡ç®—ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡
  $$
  \color{red}{ \hat{m_t} = \gamma \cdot \hat{m_{t-1}} + (1 - \beta_1) \cdot g_t } \\
  \color{red}{ m_t = \frac{\hat{m_t}}{ 1 - \beta_1^t } }
  \tag{2.8-2}
  $$
  $$
  \color{red}{ \hat{V_t} = \beta_2 \cdot \hat{V_{t-1}} + (1 - \beta_2) \cdot g_t^2 } \\
  \color{red}{ V_t = \frac{\hat{V_t}}{ 1 - \beta_2^t } }
  \tag{2.8-3}
  $$

  å…¶ä¸­çš„$\beta_1$æ§åˆ¶ä¸€é˜¶åŠ¨é‡,$\beta_2$æ§åˆ¶äºŒé˜¶åŠ¨é‡ï¼›

3. è®¡ç®—å½“å‰æ—¶åˆ»çš„ä¸‹é™æ¢¯åº¦
  $$
  \begin{align*}
  \eta_t &= \frac{\alpha}{\sqrt{V_t} + \epsilon } \cdot m_t
  \end{align*}
  \tag{2.8-4}
  $$

  å…¶ä¸­å¢åŠ çš„$\epsilon$ä¸ºäº†é˜²æ­¢åˆ†æ¯ç­‰äº$0$ï¼›

4. æ ¹æ®ä¸‹é™æ¢¯åº¦è¿›è¡Œæ›´æ–°
  $$
  \begin{align*}
  w_{t+1} &= w_t - \eta_t
  \end{align*}
  \tag{2.8-5}
  $$


-----------------------

## 3. Online Optimization Algorithm

ä¸Šé¢æè¿°çš„ä¸»è¦æ˜¯æ‰¹é‡è®­ç»ƒçš„ä¼˜åŒ–æ–¹æ³•ï¼Œæ‰¹é‡è®­ç»ƒæœ‰è‡ªèº«çš„å±€é™æ€§ï¼šé¢å¯¹é«˜ç»´é«˜æ•°æ®é‡çš„æ—¶å€™ï¼Œæ‰¹é‡å¤„ç†çš„æ–¹å¼å°±æ˜¾å¾—ç¬¨é‡å’Œä¸å¤Ÿé«˜æ•ˆã€‚å› æ­¤éœ€è¦æœ‰åœ¨çº¿å¤„ç†çš„æ–¹æ³•(Online)æ¥è§£å†³ç›¸åŒçš„é—®é¢˜ã€‚åœ¨çº¿å­¦ä¹ ç®—æ³•çš„ç‰¹ç‚¹æ˜¯ï¼šæ¯æ¥ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œå°±ç”¨è¯¥æ ·æœ¬äº§ç”Ÿçš„losså’Œæ¢¯åº¦å¯¹æ¨¡å‹è¿­ä»£ä¸€æ¬¡ï¼Œä¸€ä¸ªä¸€ä¸ªæ•°æ®åœ°è¿›è¡Œè®­ç»ƒï¼Œå› æ­¤å¯ä»¥å¤„ç†å¤§æ•°æ®é‡è®­ç»ƒå’Œåœ¨çº¿è®­ç»ƒã€‚

### 3.1 Truncated Gradient

#### 3.1.1 L1æ­£åˆ™æ³•

$$
w_{t+1} = w_{t} - \eta_t \cdot g_t - \eta_t \cdot \lambda \cdot sgn(w_t)
$$

å…¶ä¸­,
- $\lambda \in \mathbb{R} $æ˜¯ä¸€ä¸ªæ ‡é‡,ä¸”$\lambda \ge 0$,ä¸ºL1æ­£åˆ™åŒ–å‚æ•°ï¼›
- $sgn(v)$ä¸ºç¬¦å·å‡½æ•°ï¼›
- $\eta_t$ä¸ºå­¦ä¹ ç‡,é€šå¸¸å°†å…¶è®¾ç½®ä¸º$1/\sqrt{t}$çš„å‡½æ•°ï¼›
- $g_t = \nabla f(w_t) $ï¼›

#### 3.1.2 ç®€å•æˆªæ–­æ³•

ä»¥$k$ä¸ºçª—å£,å½“$t/k$ä¸ä¸ºæ•´æ•°æ—¶é‡‡ç”¨æ ‡å‡†SGDè¿›è¡Œè¿­ä»£ï¼›å½“$t/k$ä¸ºæ•´æ•°æ—¶,é‡‡ç”¨å¦‚ä¸‹æƒé‡æ›´æ–°æ–¹å¼ï¼›

$$
w_{t+1} = T_0 \left( w_t - \eta_t g_t, \theta \right)
$$

$$
T_0 (v_i, \theta) = 
\begin{cases}
0 & \quad \mid v_i \mid \le \theta \\
v_i & \quad otherwise
\end{cases}
$$

$\theta \in \mathbb{R}$æ˜¯ä¸€ä¸ªæ ‡é‡,ä¸”$\theta \ge 0$ï¼›

#### 3.1.3 æˆªæ–­æ¢¯åº¦æ³•(TG)

ç®€å•æˆªæ–­æ³•å¤ªè¿‡æ¿€è¿›,å› æ­¤TGåœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œäº†æ”¹è¿›ï¼š

$$
w_{t+1} = T_1 \left( w_t - \eta_t g_t, \quad \eta_t \lambda_t, \quad \theta \right)
$$

$$
T_1 (v_i, \alpha, \theta) = 
\begin{cases}
max(0, \quad v_i - \alpha ) & \quad v_i \in [0, \theta] \\
max(0, \quad v_i + \alpha ) & \quad v_i \in [- \theta, 0 ] \\
v_i & \quad otherwise
\end{cases}
\tag{3.1.3-1}
$$

- å…¶ä¸­$\lambda_t \in \mathbb{R}$,ä¸”$\lambda_t \ge 0$ï¼›
- TG åŒæ ·æ˜¯ä»¥$k$ä¸ºçª—å£,æ¯$k$æ­¥è¿›è¡Œä¸€æ¬¡æˆªæ–­ã€‚
  - å½“$t/k$ä¸ä¸ºæ•´æ•°æ—¶,$\lambda_t = 0$ï¼›
  - å½“$t/k$ä¸ºæ•´æ•°æ—¶,$\lambda_t = k \cdot \lambda$ã€‚
- ä»å…¬å¼$(3.1.3-1)$å¯ä»¥çœ‹å‡º,è¶…å‚æ•°$\lambda$å’Œ$\theta$å†³å®šäº†$w$çš„ç¨€ç–ç¨‹åº¦,è¿™ä¸¤ä¸ªå€¼è¶Šå¤§,åˆ™ç¨€ç–æ€§è¶Šå¼ºï¼›å°¤å…¶ä»¤$\lambda = \theta$æ—¶,åªéœ€è¦é€šè¿‡è°ƒèŠ‚ä¸€ä¸ªå‚æ•°å°±èƒ½æ§åˆ¶ç¨€ç–æ€§ã€‚

#### 3.1.4 æˆªæ–­å…¬å¼å¯¹æ¯”

![compare](/posts_res/2019-06-05-Optimization-Method/1.png)

å…¶ä¸­å·¦ä¾§æ˜¯ç®€å•æˆªæ–­æ³•çš„æˆªæ–­å…¬å¼ï¼Œå³ä¾§æ˜¯æˆªæ–­æ¢¯åº¦çš„æˆªæ–­å…¬å¼ã€‚

<br>

å…¬å¼$(3.1.3-1)$è¿›è¡Œæ”¹å†™ï¼Œæè¿°ç‰¹å¾æƒé‡æ¯ä¸ªç»´åº¦çš„æ›´æ–°æ–¹å¼:

$$
w_{t+1}^{(i)} = 
\begin{cases}
Trnc \{ ( w_t^{(i)} - \eta_t g_t^{(i)} ), \lambda_t^{TG}, \theta \} & if \quad mod(t,k) = 0 \\
w_t^{(i)} - \eta_t g_t^{(i)} & otherwise
\end{cases}
$$

$$
\lambda_t = \eta_t \lambda k
$$

$$
Trnc = 
\begin{cases}
0 & if \quad \mid w \mid \le \lambda_t^{TG} \\
w - \lambda_t^{TG} sgn(w) & if \quad \lambda_t^{TG} \le \mid w \mid \le 0 \\
w & otherwise
\end{cases}
$$

å¦‚æœä»¤$\lambda_t^{TG} = \theta$, æˆªæ–­å…¬å¼$Trnc(w, \lambda_t^{TG}, \theta)$å˜æˆ:

$$
Trnc(w, \theta, \theta) = 
\begin{cases}
0 & if \quad \mid w \mid \le 0 \\
w & otherwise
\end{cases}
$$

**æ­¤æ—¶$TG$é€€åŒ–æˆç®€å•æˆªæ–­æ³•**ã€‚

å¦‚æœä»¤$\theta = \infty$æˆªæ–­å…¬å¼$Trnc(w, \lambda_t^{TG}, \theta)$å˜æˆ:

$$
Trnc(w, \lambda_t^{TG}, \infty) = 
\begin{cases}
0 & if \quad \mid w \mid \le \lambda_t^{TG} \\
w & otherwise
\end{cases}
$$

å¦‚æœå†ä»¤$k=1$,é‚£ä¹ˆç‰¹å¾æƒé‡ç»´åº¦æ›´æ–°å…¬å¼å˜æˆ:

$$
\begin{align*}
w_{t+1}^{(i)} &= Trnc\{ (w_t^{(i)} - \eta_t g_t^{(i)}), \eta_t \lambda, \infty \} \\
&= w_t^{(i)} - \eta_t g_t^{(i)} - \eta_t \cdot \lambda \cdot sgn(w_t^{(i)}) 
\end{align*}
$$

**æ­¤æ—¶ $TG$ é€€åŒ–æˆ L1æ­£åˆ™åŒ–æ³•**ã€‚


### 3.2 FOBOSå‰å‘åå‘åˆ‡åˆ†

#### 3.2.1 FOBOSç®—æ³•åŸç†

åœ¨ FOBOS ä¸­, å°†æƒé‡çš„æ›´æ–°åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤:

$$
w^{(t+0.5)} = w^{(t)} - \eta^{(t)} \cdot G^{(t)} \\
w^{(t+1)} = argmin_w \{ \frac{1}{2} \| w - w^{(t+0.5)} \|^2 + \eta^{(t+0.5)} \cdot \psi (w) \}
\tag{3.2.1-1}
$$

- å‰ä¸€ä¸ªæ­¥éª¤å®é™…ä¸Šæ˜¯ä¸€ä¸ªæ ‡å‡†çš„æ¢¯åº¦ä¸‹é™æ­¥éª¤;
- åä¸€ä¸ªæ­¥éª¤å¯ä»¥ç†è§£ä¸ºå¯¹æ¢¯åº¦ä¸‹é™çš„ç»“æœè¿›è¡Œå¾®è°ƒ;
  - å‰ä¸€éƒ¨åˆ†ä¿è¯å¾®è°ƒå‘ç”Ÿåœ¨æ¢¯åº¦ä¸‹é™ç»“æœçš„é™„è¿‘
  - åä¸€éƒ¨åˆ†åˆ™ç”¨äºå¤„ç†æ­£åˆ™åŒ–ï¼Œäº§ç”Ÿç¨€ç–æ€§

å¦‚æœå°†å…¬å¼ $(3.2.1-1)$ ä¸­çš„ä¸¤ä¸ªæ­¥éª¤åˆäºŒä¸ºä¸€, å³å°† $w^{(t+0.5)}$ çš„è®¡ç®—å¸¦å…¥åˆ° $w^{(t+1)}$ ä¸­, æœ‰:

$$
w^{(t+1)} = argmin _w \{ \frac{1}{2} \| w - w^{(t)} + \eta^{(t)} G^{(t)} \|^2 + \eta^{(t+0.5)} \psi (w) \}
$$

ä»¤$F(w) = \frac{1}{2} || w - w^{(t)} + \eta^{(t)} G^{(t)} ||^2 + \eta^{(t+0.5)} \psi (w)$, 
å¦‚æœ$w^{(t+1)}$å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜è§£, é‚£ä¹ˆå°±å¯ä»¥æ¨æ–­$0$å‘é‡ä¸€å®šå±äº$F(w)$çš„æ¬¡æ¢¯åº¦é›†åˆ:
$$
0 \in \partial F(w) = w - w^{(t)} + \eta^{(t)} G^{(t)} + \eta^{(t+0.5)} \partial \psi (w)
$$

ç”±äº$w^{(t+1)} = argmin_w F(w)$, é‚£ä¹ˆæœ‰:
$$
0 = \{ w - w^{(t)} - \eta^{(t)} G^{(t)} + \eta^{(t+0.5)} \partial \psi (w) \} \mid_{w = w^{(t+1)}}
$$

ä¸Šå¼å®é™…ä¸Šç»™å‡ºäº† FOBOS ä¸­æƒé‡æ›´æ–°çš„å¦ä¸€ç§å½¢å¼:
$$
w^{(t+1)} = w^{(t)} - \eta^{(t)} G^{(t)} - \eta^{(t+0.5)} \partial \psi (w^{(t+1)})
$$

æˆ‘ä»¬è¿™é‡Œå¯ä»¥çœ‹åˆ°, $w^{(t+1)}$ä¸ä»…ä»…ä¸è¿­ä»£å‰çš„çŠ¶æ€$w^{(t)}$æœ‰å…³ï¼Œè€Œä¸”ä¸è¿­ä»£åçš„$\psi (w^{(t+1)})$æœ‰å…³ã€‚


#### 3.2.2 L1-FOBOS

åœ¨ L1 æ­£åˆ™åŒ–ä¸‹ï¼Œæœ‰$\psi (w) = \lambda || w ||\_1$, 
ä¸ºäº†ç®€åŒ–æè¿°, ç”¨å‘é‡$v= \[ v\_1, v\_2, \cdots, v\_N \] \in \mathbb{R}^N$ æ¥è¡¨ç¤º$w^{(t+0.5)}$, 
ç”¨æ ‡é‡$\hat{\lambda} \in \mathbb{R}$ æ¥è¡¨ç¤º $\eta\_{t+0.5} \lambda$, å¹¶å°†å…¬å¼$(3.2.1-1)$ç­‰å·å³è¾¹æŒ‰ç»´åº¦å±•å¼€:
$$
w^{(t+1)} = argmin_w \sum_{i=1}^N ( \frac{1}{2} (w_i - v_i)^2 + \hat{\lambda} \mid w_i \mid )
\tag{3.2.2-1}
$$

å¯ä»¥çœ‹åˆ°,åœ¨æ±‚å’Œå…¬å¼$\sum_{i=1}^N \( \frac{1}{2} (w_i - v_i)^2 + \hat{\lambda} \mid w_i \mid \)$ ä¸­çš„æ¯ä¸€é¡¹éƒ½æ˜¯å¤§äºç­‰äº $0$ çš„,
æ‰€ä»¥å…¬å¼$(3.2.2-1)$å¯ä»¥æ‹†è§£æˆå¯¹ç‰¹å¾æƒé‡$w$æ¯ä¸€ç»´åº¦å•ç‹¬æ±‚è§£:
$$
w^{(t+1)}_i = argmin_{w_i} ( \frac{1}{2} (w_i - v_i)^2 + \hat{\lambda} \mid w_i \mid )
$$

å› æ­¤, å¾—åˆ°åœ¨ FOBOS åœ¨ L1 æ­£åˆ™åŒ–æ¡ä»¶ä¸‹ï¼Œç‰¹å¾æƒé‡çš„å„ä¸ªç»´åº¦æ›´æ–°çš„æ–¹å¼ä¸º:
$$
\begin{align*}
w^{(t+1)}_i &= sgn(v_i) max (0, \mid v_i - \hat{\lambda}) \\
&= sgn(w_i^{(t)} - \eta^{(t)} g^{(t)}_i ) max \{ 0, \mid w^{(t)}_i - \eta_t \cdot g_i^{(t)} \mid - \eta^{(t+0.5)} \lambda \}
\end{align*}
\tag{3.2.2-2}
$$

å…¶ä¸­, $g_i^{(t)}$ ä¸ºæ¢¯åº¦ $G^{(t)}$ åœ¨ç»´åº¦ $i$ ä¸Šçš„å–å€¼ã€‚

#### 3.2.3 L1-FOBOSä¸TGçš„å…³ç³»

å¯¹äº L1-FOBOS ç‰¹å¾æƒé‡çš„å„ä¸ªç»´åº¦æ›´æ–°å…¬å¼$(3.2.2-2)$ï¼Œä¹Ÿå¯ä»¥å†™ä½œå¦‚ä¸‹å½¢å¼:

$$
w^{(t+1)}_i = 
\begin{cases}
0 & \quad \mid w^{(t)}_i - \eta^{(t)} \cdot g^{(t)}_i \mid \le \eta^{(t+0.5)} \lambda \\
\left( w^{(t)}_i - \eta^{(t)} \cdot g^{(t)}_i \right) - \eta^{(t+0.5)} \cdot \lambda sgn(w^{(t)}_i - \eta^{(t)} g^{(t)}_i) & \quad otherwise
\end{cases}
\tag{3.2.3-1}
$$

å¼$(3.2.3-1)$æˆªæ–­çš„å«ä¹‰æ˜¯ï¼šå½“ä¸€æ¡æ ·æœ¬äº§ç”Ÿçš„æ¢¯åº¦ä¸è¶³ä»¥ä»¤å¯¹åº”ç»´åº¦ä¸Šçš„æƒé‡å€¼å‘ç”Ÿè¶³å¤Ÿå¤§çš„å˜åŒ– $( \eta^{(t+0.5)} \cdot \lambda )$, 
åˆ™è®¤ä¸ºåœ¨æœ¬æ¬¡æ›´æ–°è¿‡ç¨‹ä¸­è¯¥ç»´åº¦ä¸å¤Ÿé‡è¦ï¼Œåº”å½“ä»¤å…¶æƒé‡ä¸º$0$ã€‚

åŒæ—¶å¼$(3.2.3-1)$ä¸TGçš„ç‰¹å¾æƒé‡æ›´æ–°å…¬å¼$(3.1.3-1)$å¯¹æ¯”, å‘ç°å¦‚æœä»¤$ \theta = \infty, k = 1, \lambda^{(t)}_{TG} = \eta^{(t+0.5} \lambda $,åˆ™L1-FOBOSä¸TGå®Œå…¨ä¸€è‡´ï¼Œå› æ­¤å¯ä»¥è®¤ä¸ºL1-FOBOSæ˜¯TGåœ¨ç‰¹å®šæ¡ä»¶ä¸‹çš„ç‰¹æ®Šå½¢å¼ã€‚

### 3.3 RDAæ­£åˆ™å¯¹å¶å¹³å‡

ç®€å•æˆªæ–­ã€TGã€FOBOS éƒ½æ˜¯å»ºç«‹åœ¨ SGD çš„åŸºç¡€ä¹‹ä¸Šçš„ï¼Œå±äºæ¢¯åº¦ä¸‹é™ç±»å‹çš„æ–¹æ³•ï¼Œè¿™ç±»å‹æ–¹æ³•çš„ä¼˜ç‚¹å°±æ˜¯**ç²¾åº¦æ¯”è¾ƒé«˜**ï¼Œ
å¹¶ä¸”TGã€FOBOSä¹Ÿéƒ½èƒ½åœ¨ç¨€ç–æ€§ä¸Šå¾—åˆ°æå‡ã€‚ä½†æ˜¯æœ‰äº›å…¶å®ƒç±»å‹çš„ç®—æ³•ï¼Œä¾‹å¦‚RDAï¼Œæ˜¯ä»å¦ä¸€ä¸ªæ–¹é¢æ¥æ±‚è§£ Online Optimization,
å¹¶ä¸”æ›´æœ‰æ•ˆåœ°æå‡äº†ç‰¹å¾æƒé‡çš„ç¨€ç–æ€§ã€‚

#### 3.3.1 RDAç®—æ³•åŸç†

åœ¨RDAä¸­ï¼Œç‰¹å¾æƒé‡çš„æ›´æ–°ç­–ç•¥ä¸º:
$$
w^{(t+1)} = argmin_w { \frac{1}{t} \sum_{r=1}^t < G^{(r)}, w > + \psi (w) + \frac{\beta^{(t)}}{t} h(w) }
\tag{3.3.1-1}
$$

å…¶ä¸­ï¼Œ$< G^{(r)}, w >$è¡¨ç¤ºæ¢¯åº¦ $G^{(r)}$å¯¹ $w$ çš„ç§¯åˆ†å¹³å‡å€¼(ç§¯åˆ†ä¸­å€¼); $\psi (w)$ ä¸ºæ­£åˆ™é¡¹ï¼›$h(w)$ä¸ºä¸€ä¸ªè¾…åŠ©çš„ä¸¥æ ¼å‡¸å‡½æ•°ï¼›
$ { \beta^{(t)} | t \ge 1 }$æ˜¯ä¸€ä¸ªéè´Ÿä¸”éè‡ªå‡åºåˆ—ã€‚æœ¬è´¨ä¸Šï¼Œå…¬å¼$(3.3.1-1)$ä¸­åŒ…å«äº†3ä¸ªéƒ¨åˆ†ï¼š
- çº¿æ€§å‡½æ•° $ \frac{1}{t} \sum_{r=1}^t < G^{(t)}, w > $, åŒ…å«äº†ä¹‹å‰æ‰€æœ‰æ¢¯åº¦(æˆ–æ¬¡æ¢¯åº¦)çš„å¹³å‡å€¼(dual average);
- æ­£åˆ™é¡¹ $\psi (w)$;
- é¢å¤–æ­£åˆ™é¡¹ $\frac{\beta^{(t)}}{t} h(w)$, è¿™æ˜¯ä¸ªä¸¥æ ¼å‡¸å‡½æ•°;

#### 3.3.2 L1-RDA

ä»¤$\psi (w) = \lambda || w ||\_1$ï¼Œå¹¶ä¸”ç”±äº$h(w)$æ˜¯ä¸€ä¸ªå…³äº$w$çš„ä¸¥æ ¼å‡¸å‡½æ•°ï¼Œä¸å¦¨ä»¤ $h(w) = \frac{1}{2} || w ||\_2^2 $,
æ­¤å¤–ï¼Œå°†éè´Ÿéè‡ªå‡åºåˆ— $ \lbrace \beta^{(t)} | t \ge 1 \rbrace $ å®šä¹‰ä¸º $ \beta^{(t)} = \gamma \sqrt{t} $ï¼Œå°†L1æ­£åˆ™åŒ–ä»£å…¥å…¬å¼$(3.3.1-1)$æœ‰:
$$
w^{(t+1)} = argmin_w \lbrace \frac{1}{t} \sum_{r=1}^t < G^{(r)}, w > + \lambda | w |_1 + \frac{\gamma}{2 \sqrt{t}} | w | _2^2 \rbrace
\tag{3.3.2-1}
$$

é’ˆå¯¹ç‰¹å¾æƒé‡çš„å„ä¸ªç»´åº¦å°†å…¶æ‹†è§£æˆ N ä¸ªç‹¬ç«‹çš„æ ‡é‡æœ€å°åŒ–é—®é¢˜:
$$
minimize_{w_i \in \mathbb{R}} \lbrace \bar{g}_i^{(t)} w_i + \lambda \mid w_i \mid + \frac{\gamma}{2\sqrt{t}} w_i^2 \rbrace
\tag{3.3.2-2}
$$

è¿™é‡Œ $ \lambda > 0, \frac{\gamma}{\sqrt{t}} > 0, \bar{g}\_i^{(t)} = \frac{1}{t} \sum\_{r=1}^t g\_i^{(r)} $, 
å…¬å¼$(3.3.2-2)$å°±æ˜¯ä¸€ä¸ªæ— çº¦æŸçš„éå¹³æ»‘æœ€ä¼˜åŒ–é—®é¢˜ã€‚

$$\cdots \cdots$$

$$\cdots \cdots$$

ä¹‹åå¯ä»¥å¾—åˆ°L1-RDAç‰¹å¾æƒé‡çš„å„ä¸ªç»´åº¦æ›´æ–°çš„æ–¹å¼ä¸ºï¼š
$$
w_i^{(t)} = 
\begin{cases}
0 & \quad if \quad \mid \bar{g}_i^{(t)} \mid < \lambda \\
-\frac{\sqrt{t}}{\gamma} ( \bar{g}_i^{(t)} - \lambda \cdot sgn( \bar{g}_i^{(t)} ) ) & \quad otherwise
\end{cases}
\tag{3.3.2-3}
$$

è¿™é‡Œå‘ç°ï¼Œå½“æŸä¸ªç»´åº¦ä¸Šç´¯ç§¯æ¢¯åº¦å¹³å‡å€¼çš„ç»å¯¹å€¼ $g_i^{(t)}$ å°äºé˜ˆå€¼ğœ†çš„æ—¶å€™ï¼Œè¯¥ç»´åº¦æƒé‡å°†è¢«ç½® $0$ï¼Œç‰¹å¾æƒé‡çš„ç¨€ç–æ€§ç”±æ­¤äº§ç”Ÿã€‚

#### 3.3.3 L1-RDAä¸L1-FOBOSçš„æ¯”è¾ƒ

åœ¨ $3.2.2$ ä¸­æˆ‘ä»¬çœ‹åˆ°äº† L1-FOBOS å®é™…ä¸Šæ˜¯ TG çš„ä¸€ç§ç‰¹æ®Šå½¢å¼, åœ¨ L1-FOBOS ä¸­ï¼Œè¿›è¡Œ **æˆªæ–­** çš„åˆ¤å®šæ¡ä»¶æ˜¯
$ | w\_i^{(t)} - \eta^{(t)} g\_i^{(t)} | \le \lambda^{(t)}\_{TG} = \eta^{(t+0.5)} \lambda $ ã€‚
é€šå¸¸ä¼šå®šä¹‰ $\eta$ ä¸ºä¸ $1$ æ­£ç›¸å…³çš„å‡½æ•° $(\eta = \Theta (\frac{1}{\sqrt{t}}))$, 
å› æ­¤ L1-FOBOS çš„**æˆªæ–­é˜ˆå€¼**ä¸º $\Theta (\frac{1}{\sqrt{t}})) \lambda $, éšç€ $t$ çš„å¢åŠ , è¿™ä¸ªé˜ˆå€¼ä¼šé€æ¸é™ä½ã€‚

ç›¸æ¯”è¾ƒè€Œè¨€ï¼Œä»$(3.3.2-3)$å¯ä»¥çœ‹å‡º, L1-RDA çš„**æˆªæ–­é˜ˆå€¼**ä¸º $\lambda$, æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œå¹¶ä¸éšç€ $t$ è€Œå˜åŒ–, 
å› æ­¤å¯ä»¥è®¤ä¸º L1-RDA æ¯” L1-FOBOS åœ¨æˆªæ–­åˆ¤å®šä¸Šæ›´åŠ æ¿€è¿›, è¿™ç§æ€§è´¨ä½¿å¾— L1-RDA æ›´å®¹æ˜“äº§ç”Ÿç¨€ç–æ€§;
æ­¤å¤–ï¼ŒRDA ä¸­åˆ¤å®šå¯¹è±¡æ˜¯æ¢¯åº¦çš„ç´¯åŠ å¹³å‡å€¼ $\bar{g}\_i^{(t)}$, ä¸åŒäº TG æˆ– L1-FOBOS ä¸­é’ˆå¯¹å•æ¬¡æ¢¯åº¦è®¡ç®—çš„ç»“æœè¿›è¡Œåˆ¤å®š,
é¿å…äº†ç”±äºæŸäº›ç»´åº¦ç”±äºè®­ç»ƒä¸è¶³å¯¼è‡´æˆªæ–­çš„é—®é¢˜ã€‚å¹¶ä¸”é€šè¿‡è°ƒèŠ‚ $\lambda$ ä¸€ä¸ªå‚æ•°ï¼Œå¾ˆå®¹æ˜“åœ¨ç²¾åº¦å’Œç¨€ç–æ€§ä¸Šè¿›è¡Œæƒè¡¡


### 3.4 FTRL

- ç¡®ä¿æ–°çš„æƒé‡å’Œå†å²æƒé‡ä¸åç¦»å¤ªè¿œ
- L1æ­£åˆ™ç¨€ç–æ€§çº¦æŸ


------------

> - [ä¸€ä¸ªæ¡†æ¶çœ‹æ‡‚ä¼˜åŒ–ç®—æ³•ä¹‹å¼‚åŒ SGD/AdaGrad/Adam](https://zhuanlan.zhihu.com/p/32230623)
> - [SGDã€Momentumã€RMSpropã€AdamåŒºåˆ«ä¸è”ç³»](https://zhuanlan.zhihu.com/p/32488889)
> - [An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)
> - [åœ¨çº¿æœ€ä¼˜åŒ–æ±‚è§£(Online Optimization)-å†¯æ‰¬](/posts_res/2019-06-05-Optimization-Method/online_optimization_fengyang.pdf)
> - [æ¯”Momentumæ›´å¿«ï¼šæ­å¼€Nesterov Accelerated Gradientçš„çœŸé¢ç›®](https://zhuanlan.zhihu.com/p/22810533)
> - [æ·±åº¦å­¦ä¹ æœ€å…¨ä¼˜åŒ–æ–¹æ³•æ€»ç»“æ¯”è¾ƒï¼ˆSGD,Adagrad,Adadelta,Adam,Adamax,Nadamï¼‰](https://zhuanlan.zhihu.com/p/22252270)
> - [Deep Learning æœ€ä¼˜åŒ–æ–¹æ³•ä¹‹AdaGrad](https://zhuanlan.zhihu.com/p/29920135)
